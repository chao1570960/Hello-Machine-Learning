{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of trainingFeatures 16\n",
      "size of trainingCategories 7494\n",
      "feature key 0\n",
      "feature key 1\n",
      "feature key 2\n",
      "feature key 3\n",
      "feature key 4\n",
      "feature key 5\n",
      "feature key 6\n",
      "feature key 7\n",
      "feature key 8\n",
      "feature key 9\n",
      "feature key 10\n",
      "feature key 11\n",
      "feature key 12\n",
      "feature key 13\n",
      "feature key 14\n",
      "feature key 15\n",
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/jupyterlab/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/anaconda3/envs/jupyterlab/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13a3bacf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13a3bacf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def formatFeatures(features):\n",
    "    formattedFeatures = dict()\n",
    "    numColumns = features.shape[1]\n",
    "    for i in range(0, numColumns):\n",
    "        formattedFeatures[str(i)] = features[:, i]\n",
    "    return formattedFeatures\n",
    "\n",
    "def defineFeatureColumns(features):\n",
    "    featureColumns = []\n",
    "    for key in features.keys():\n",
    "        featureColumns.append(tf.feature_column.numeric_column(key=key, dtype=tf.dtypes.float32))\n",
    "        print(\"feature key\", key)\n",
    "    return featureColumns\n",
    "\n",
    "def train(features, labels, batchSize):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    return dataset.shuffle(1000).repeat().batch(batchSize)\n",
    "########################################################################\n",
    "\n",
    "trainingData = pd.read_csv(\"training-data.csv\", header=None).as_matrix()\n",
    "testData = pd.read_csv(\"test-data.csv\", header=None).as_matrix()\n",
    "\n",
    "trainingFeatures = formatFeatures(trainingData[:, :-1])\n",
    "trainingCategories = trainingData[:, -1:]\n",
    "\n",
    "print(\"size of trainingFeatures\", len(trainingFeatures))\n",
    "print(\"size of trainingCategories\", len(trainingCategories))\n",
    "\n",
    "testFeatures = formatFeatures(testData[:, :-1])\n",
    "testCategories = testData[:, -1:]\n",
    "\n",
    "\n",
    "featureColumns = defineFeatureColumns(trainingFeatures)\n",
    "\n",
    "# Define, train and export your estimator as usual\n",
    "estimator = tf.estimator.DNNClassifier(hidden_units=[25, 100, 45],\n",
    "                                       n_classes=10,\n",
    "                                       feature_columns=featureColumns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 26.794441, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 26.794441, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 67.5177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 67.5177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4175168, step = 100 (1.483 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4175168, step = 100 (1.483 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.80297196.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.80297196.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x13a4b7eb8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn = lambda:train(trainingFeatures, trainingCategories, 1000)\n",
    "\n",
    "estimator.train(input_fn=input_fn, max_steps=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = lambda:train(testFeatures, testCategories, 1000)\n",
    "results = estimator.predict(input_fn=test_input_fn)\n",
    "\n",
    "#for result in results:\n",
    "#    print('result: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature key 0\n",
      "feature key 1\n",
      "feature key 2\n",
      "feature key 3\n",
      "feature key 4\n",
      "feature key 5\n",
      "feature key 6\n",
      "feature key 7\n",
      "feature key 8\n",
      "feature key 9\n",
      "feature key 10\n",
      "feature key 11\n",
      "feature key 12\n",
      "feature key 13\n",
      "feature key 14\n",
      "feature key 15\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Export includes no default signature!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Export includes no default signature!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g/model.ckpt-200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/mh/t53x_cmn10x9md9752q928jrk38mgn/T/tmp_i28un2g/model.ckpt-200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./temp-b'1577958820'/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./temp-b'1577958820'/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel, b'./1577958820'\n"
     ]
    }
   ],
   "source": [
    "def eval_input_receiver_fn():\n",
    "  serialized_tf_example = tf.compat.v1.placeholder(\n",
    "      dtype=tf.string, shape=[None], name='input_example_placeholder')\n",
    "  # This *must* be a dictionary containing a single key 'examples', which\n",
    "  # points to the input placeholder.\n",
    "  receiver_tensors = {'examples': serialized_tf_example}\n",
    "\n",
    "  featureColumns_tmp = defineFeatureColumns(trainingFeatures)\n",
    "  featureColumns_tmp.append(tf.feature_column.numeric_column(key=\"label\", dtype=tf.dtypes.int64))\n",
    "  \n",
    "  feature_spec =  tf.feature_column.make_parse_example_spec(featureColumns_tmp)\n",
    "  features = tf.io.parse_example(serialized_tf_example, feature_spec)\n",
    "\n",
    "  return tfma.export.EvalInputReceiver(\n",
    "    features=features,  # feature spec\n",
    "    receiver_tensors=receiver_tensors, # tensor of raw placeholder\n",
    "    labels=features['label'])\n",
    "\n",
    "\n",
    "export_dir=\"./\"\n",
    "\n",
    "# Also export the EvalSavedModel\n",
    "mymodel = tfma.export.export_eval_savedmodel(\n",
    "  estimator=estimator,\n",
    "  export_dir_base=export_dir,\n",
    "  eval_input_receiver_fn=eval_input_receiver_fn)\n",
    "\n",
    "print(\"mymodel,\", mymodel)\n",
    "mymodel = str(mymodel, \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liulu51/test-script/tf-TFMA/./1577958820\n",
      "WARNING:tensorflow:Tensorflow version (2.0.0) found. Note that TFMA support for TF 2.0 is currently in beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.0.0) found. Note that TFMA support for TF 2.0 is currently in beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/liulu51/test-script/tf-TFMA/./1577958820/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/liulu51/test-script/tf-TFMA/./1577958820/variables/variables\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "eval_saved_model_path = os.path.join(os.getcwd(), mymodel)\n",
    "print(eval_saved_model_path)\n",
    "\n",
    "eval_shared_model = tfma.default_eval_shared_model(\n",
    "    eval_saved_model_path=eval_saved_model_path )\n",
    "\n",
    "\n",
    "# convert ./training-data.csv to ./train.tfrecords\n",
    "\n",
    "eval_result = tfma.run_model_analysis(\n",
    "    eval_shared_model=eval_shared_model,\n",
    "    data_location='train.tfrecords',\n",
    "    file_format='tfrecords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51514f90ff264f38bbfd7b137199b5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SlicingMetricsViewer(config={'weightedExamplesColumn': 'post_export_metrics/example_count'}, data=[{'slice': '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfma.view.render_slicing_metrics(eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
